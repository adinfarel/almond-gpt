vocab_size: 8192
paths:
  text_path: data/raw/input.txt
  vocab_output: models/tokenizer/vocab.json
  merges_output: models/tokenizer/merges.json